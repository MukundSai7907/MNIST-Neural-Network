{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB2fS2wCM-by"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import sklearn.metrics as sm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NObciVgTOzxW"
      },
      "source": [
        "We are assuming that Wi is the weight matrix that maps from layer i to i+1\n",
        "\n",
        "We also assume that x inputs are a1, hidden layer is a2 and so on\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neteztxqNIuK"
      },
      "outputs": [],
      "source": [
        "class CLF:\n",
        "  def __init__(self, x_train, y_train, x_test, y_test):\n",
        "    self.x_train = x_train\n",
        "    self.y_train = y_train\n",
        "    self.x_test = x_test\n",
        "    self.y_test = y_test\n",
        "    self.x_train, self.x_test = self.x_train / 255.0, self.x_test / 255.0\n",
        "\n",
        "    self.batch_size = 32\n",
        "    self.learning_rate = 0.01\n",
        "    self.train_steps = len(self.x_train) // self.batch_size\n",
        "    self.epochs = 5 \n",
        "\n",
        "    self.d = 28*28\n",
        "    self.d1 = 300\n",
        "    self.k = 10\n",
        "    \n",
        "    self.W1 = np.random.uniform(-1 , 1 , (self.d1 , self.d))\n",
        "    self.W2 = np.random.uniform(-1 , 1 , (self.k , self.d1))\n",
        "\n",
        "\n",
        "\n",
        "  def sigmoid(self, a):\n",
        "    return 1 / (1 + np.exp(-a))\n",
        "\n",
        "  def softmax(self, a):\n",
        "    exps = np.exp(a)\n",
        "    return exps / np.sum(exps)\n",
        "\n",
        "  def sigmoid_der(self, a):\n",
        "    return np.multiply(self.sigmoid(a), (1 - self.sigmoid(a)))\n",
        "\n",
        "  def forward_pass(self, inp):\n",
        "    \n",
        "    z2 = np.matmul(self.W1 , inp)\n",
        "    a2 = self.sigmoid(z2)\n",
        "\n",
        "    z3 = np.matmul(self.W2 , a2)\n",
        "    a3 = self.softmax(z3)\n",
        "\n",
        "    return a2 , a3\n",
        "\n",
        "\n",
        "  def calc_loss(self, y_true, y_pred):\n",
        "    return -np.dot(np.squeeze(y_true) , np.squeeze(np.log(y_pred)))\n",
        "\n",
        "  \n",
        "  def compute_grad(self, y_true, y_pred, a2, a1):\n",
        "    delta3 = y_pred - y_true\n",
        "\n",
        "    delta2 = np.multiply((np.matmul(np.transpose(self.W2) , delta3)) , self.sigmoid_der(a2))\n",
        "\n",
        "\n",
        "    del2 = np.matmul(delta3 , np.transpose(a2))\n",
        "    del1 = np.matmul(delta2, np.transpose(a1))\n",
        "\n",
        "    return del1 , del2\n",
        "\n",
        "\n",
        "  def encode(self,y):\n",
        "    temp = [0,0,0,0,0,0,0,0,0,0]\n",
        "    temp[y] = 1\n",
        "    temp = np.array(temp)\n",
        "    temp = temp.reshape(10,1)\n",
        "    return temp\n",
        "  \n",
        "\n",
        "  def train(self):\n",
        "    for epoch in range(self.epochs):\n",
        "      for step in range(self.train_steps):\n",
        "        delw1 = np.zeros((self.d1 , self.d))\n",
        "        delw2 = np.zeros((self.k , self.d1))\n",
        "\n",
        "\n",
        "        for b in range(step * self.batch_size, (step+1) * self.batch_size): \n",
        "          temp_x_train = self.x_train[b].reshape(784,1)\n",
        "\n",
        "          temp_y_train = self.encode(self.y_train[b])\n",
        "\n",
        "          a2 , yhat = self.forward_pass(temp_x_train)\n",
        "\n",
        "          loss = self.calc_loss(temp_y_train, yhat)\n",
        "\n",
        "          del1 , del2 = self.compute_grad(temp_y_train , yhat, a2, temp_x_train)\n",
        "\n",
        "          delw1 += del1\n",
        "          delw2 += del2\n",
        "\n",
        "        self.W1 = self.W1 - ((self.learning_rate/self.batch_size) * delw1)\n",
        "        self.W2 = self.W2 - ((self.learning_rate/self.batch_size) * delw2)\n",
        "  \n",
        "\n",
        "  def predict(self,x_test,y_test):\n",
        "    x_test = x_test.reshape(784,1)\n",
        "    a2, yhat = self.forward_pass(x_test)\n",
        "\n",
        "\n",
        "    return yhat\n",
        "\n",
        "  def evaluate(self):\n",
        "    yhat_vec = []\n",
        "    for i in range(len(self.x_test)):\n",
        "      temp_y = self.predict(self.x_test[i], self.y_test[i])\n",
        "      yhat_vec.append(np.argmax(temp_y))\n",
        "    acc = sm.accuracy_score(self.y_test , yhat_vec)\n",
        "    print(f'Accuracy is: {acc}')\n",
        "\n",
        "    return acc\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT6EwD4Qkzoh"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train) , (x_test, y_test) = mnist.load_data()\n",
        "total_size = len(x_train)\n",
        "ANN_25 = CLF(x_train[0:math.ceil(total_size * 0.25)] , y_train[0:math.ceil(total_size * 0.25)] , x_test , y_test)\n",
        "ANN_50 = CLF(x_train[0:math.ceil(total_size * 0.50)] , y_train[0:math.ceil(total_size * 0.50)] , x_test , y_test)\n",
        "ANN_75 = CLF(x_train[0:math.ceil(total_size * 0.75)] , y_train[0:math.ceil(total_size * 0.75)] , x_test , y_test)\n",
        "ANN_100 = CLF(x_train , y_train , x_test , y_test)\n",
        "ANN_25.train()\n",
        "ANN_50.train()\n",
        "ANN_75.train()\n",
        "ANN_100.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrqL2wo7sMFD",
        "outputId": "cb033d75-f26d-479b-dbd9-2de0f92c9609"
      },
      "outputs": [],
      "source": [
        "LC = []\n",
        "LC.append(ANN_25.evaluate())\n",
        "LC.append(ANN_50.evaluate())\n",
        "LC.append(ANN_75.evaluate())\n",
        "LC.append(ANN_100.evaluate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "QoVgUlj7KMji",
        "outputId": "f205621d-eb9f-4ff6-fb8b-2ce755b00db5"
      },
      "outputs": [],
      "source": [
        "Error = 1 - np.array(LC)\n",
        "print(f'The accuracies are {LC}')\n",
        "print(f'The Errors are: {Error}')\n",
        "plt.plot([25,50,75,100] , LC)\n",
        "plt.xlabel('Percentage of total dataset used')\n",
        "plt.ylabel('Test set accuracy')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Q5_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
